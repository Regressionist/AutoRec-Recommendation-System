{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from sklearn.utils import shuffle\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe size: (240447, 14277)\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('ratings.csv',names=['userID','movieID','rating','time'])\n",
    "df.drop('time',axis=1,inplace=True)\n",
    "users=[k for k,v in df['userID'].value_counts().iteritems() if v>2]\n",
    "movies=[k for k,v in df['movieID'].value_counts().iteritems() if v>10]\n",
    "df=df[(df['userID'].isin(users)) & (df['movieID'].isin(movies))]\n",
    "#df=df.sample(frac=1).reset_index(drop=True)\n",
    "df=df.pivot(index='userID',columns='movieID',values='rating')\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "print ('Dataframe size: {}'.format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataframe size: (220000, 14277)\n",
      "Test dataframe size: (10447, 14277)\n",
      "Validation dataframe size: (10000, 14277)\n"
     ]
    }
   ],
   "source": [
    "train_df=(df.loc[:220000-1])\n",
    "print ('Train dataframe size: {}'.format(train_df.shape))\n",
    "test_df=df.loc[230000:].reset_index(drop=True)\n",
    "print ('Test dataframe size: {}'.format(test_df.shape))\n",
    "val_df=df.loc[220000:230000-1].reset_index(drop=True)\n",
    "print ('Validation dataframe size: {}'.format(val_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size_1, hidden_size_2):\n",
    "        super(VAE,self).__init__()\n",
    "        self.input_size=input_size\n",
    "        self.hidden_size_1=hidden_size_1\n",
    "        self.hidden_size_2=hidden_size_2\n",
    "        \n",
    "        self.encoder_linear_l1=nn.Linear(input_size, hidden_size_1)\n",
    "        self.encoder_linear_l2=nn.Linear(hidden_size_1, 2*hidden_size_2)\n",
    "        \n",
    "        self.decode_linear_l1=nn.Linear(hidden_size_2, hidden_size_1)\n",
    "        self.decode_linear_l2=nn.Linear(hidden_size_1, input_size)\n",
    "        \n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, input_ratings):\n",
    "        mu,logvar=self.encode(input_ratings)\n",
    "        param=self.reparameterize(mu,logvar)\n",
    "        decoded=self.decode(param)\n",
    "        return decoded,mu,logvar\n",
    "    \n",
    "    def encode(self, input_ratings):\n",
    "        enc_out=F.relu(self.encoder_linear_l1(input_ratings))\n",
    "        enc_out=self.encoder_linear_l2(enc_out)\n",
    "        log_var=enc_out[:,self.hidden_size_2:]\n",
    "        mu=enc_out[:,:self.hidden_size_2]\n",
    "        return mu, log_var\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std=torch.exp(0.5*logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "    \n",
    "    def decode(self,param):\n",
    "        dec_out=F.relu(self.decode_linear_l1(param))\n",
    "        dec_out=self.decode_linear_l2(dec_out)\n",
    "        return dec_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_criterion(decoded,input_ratings,mu,logvar,annealing_coef):\n",
    "    #bce_loss=-torch.mean(torch.sum(input_ratings*decoded,-1))\n",
    "    mse_loss=criterion(decoded,input_ratings)\n",
    "    kl_divg=-0.5*torch.mean(torch.sum(mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar), dim=1))\n",
    "    return mse_loss+annealing_coef*kl_divg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_minibatch(input_ratings, vae, optimizer):\n",
    "    vae.train()\n",
    "    optimizer.zero_grad()\n",
    "    input_ratings=input_ratings.type(torch.cuda.FloatTensor)\n",
    "    mask=input_ratings!=0\n",
    "    mask=mask.type(torch.cuda.FloatTensor)\n",
    "    #input_ratings=F.normalize(input_ratings,p=1)\n",
    "    output_ratings,mu,logvar=vae(input_ratings)\n",
    "    loss=loss_criterion(output_ratings*mask,input_ratings,mu,logvar,annealing_coef=0.002)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(input_ratings, vae):\n",
    "    with torch.no_grad():\n",
    "        vae.eval()\n",
    "        mask=input_ratings!=0\n",
    "        mask=mask.type(torch.cuda.FloatTensor)\n",
    "        input_ratings=input_ratings.type(torch.cuda.FloatTensor)\n",
    "        output_ratings,mu,logvar=vae(input_ratings)\n",
    "        output_ratings=output_ratings*mask\n",
    "        #input_ratings=F.normalize(input_ratings,p=1)\n",
    "        loss=0\n",
    "        for i in range(output_ratings.size(0)):\n",
    "            indices=torch.nonzero(mask[i])\n",
    "            l=0\n",
    "            for idx in indices:\n",
    "                l+=(input_ratings[i][idx]-output_ratings[i][idx])**2\n",
    "            loss+=l/indices.size(0)\n",
    "        #loss=torch.mean(torch.sum((output_ratings-input_ratings)**2,-1)/torch.sum(mask,-1))\n",
    "        return (torch.sqrt(loss/mask.size(0))).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae=VAE(input_size=train_df.shape[1], hidden_size_1=512, hidden_size_2=256)\n",
    "optimizer=optim.Adam(vae.parameters())\n",
    "device=torch.device('cuda')\n",
    "criterion=nn.MSELoss()\n",
    "vae=vae.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_mask=val_df.copy()\n",
    "#val_mask[~val_mask.isnull()] = 1  # not nan\n",
    "#val_mask[val_mask.isnull()] = 0   # nan\n",
    "val_df[val_df.isnull()] = 0   # nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_users_val=torch.from_numpy(val_df.values).to(device).detach()\n",
    "#mask_val=torch.from_numpy(val_mask.values).to(device).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('model_VAE.pth')\n",
    "autorec.load_state_dict(checkpoint['autorec_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "autorec.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1 | Step: 1/5 | Training Loss: 0.6869275914505124 | Validation RMSE: 2.9772\n",
      "%---Saving the model---%\n",
      "Batch: 1 | Step: 2/5 | Training Loss: 0.32552036418928765 | Validation RMSE: 3.151\n",
      "Batch: 1 | Step: 3/5 | Training Loss: 0.30914287065388635 | Validation RMSE: 3.4288\n",
      "Batch: 1 | Step: 4/5 | Training Loss: 0.30104814129299484 | Validation RMSE: 3.6827\n",
      "Batch: 1 | Step: 5/5 | Training Loss: 0.3041689707606565 | Validation RMSE: 3.9071\n",
      "Batch: 2 | Step: 1/5 | Training Loss: 0.2977231444674544 | Validation RMSE: 4.01\n",
      "Batch: 2 | Step: 2/5 | Training Loss: 0.30149137281114236 | Validation RMSE: 4.0952\n",
      "Batch: 2 | Step: 3/5 | Training Loss: 0.2985427894454915 | Validation RMSE: 4.1102\n",
      "Batch: 2 | Step: 4/5 | Training Loss: 0.29397519427584484 | Validation RMSE: 4.1139\n",
      "Batch: 2 | Step: 5/5 | Training Loss: 0.2993569487298373 | Validation RMSE: 4.1198\n",
      "Batch: 3 | Step: 1/5 | Training Loss: 0.29696795280324295 | Validation RMSE: 4.1105\n",
      "Batch: 3 | Step: 2/5 | Training Loss: 0.29940205957973376 | Validation RMSE: 4.1111\n",
      "Batch: 3 | Step: 3/5 | Training Loss: 0.29562920151511207 | Validation RMSE: 4.0975\n",
      "Batch: 3 | Step: 4/5 | Training Loss: 0.2924120961688459 | Validation RMSE: 4.084\n",
      "Batch: 3 | Step: 5/5 | Training Loss: 0.29938803432742134 | Validation RMSE: 4.0759\n",
      "Batch: 4 | Step: 1/5 | Training Loss: 0.29666213068412617 | Validation RMSE: 4.0566\n",
      "Batch: 4 | Step: 2/5 | Training Loss: 0.3005777776706964 | Validation RMSE: 4.0521\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-20e1b06e896d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mrunning_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m44000\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mval_rmse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_users_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Batch: {} | Step: {}/{} | Training Loss: {} | Validation RMSE: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m44000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrunning_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_rmse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mrunning_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-d831d7a18c28>\u001b[0m in \u001b[0;36mvalidation\u001b[0;34m(input_ratings, vae)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0ml\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0moutput_ratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#loss=torch.mean(torch.sum((output_ratings-input_ratings)**2,-1)/torch.sum(mask,-1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_batches=60\n",
    "val_benchmark=10\n",
    "\n",
    "\n",
    "\n",
    "for batch in range(0,num_batches):\n",
    "    running_loss=0\n",
    "    #train_df = shuffle(train_df)\n",
    "    for i in range(0,train_df.shape[0],100):\n",
    "        #print(i)\n",
    "        tdf=train_df.loc[i:i+100-1].copy()\n",
    "        #train_mask=tdf.copy()\n",
    "        #train_mask[~train_mask.isnull()] = 1  # not nan\n",
    "        #train_mask[train_mask.isnull()] = 0   # nan\n",
    "        tdf[tdf.isnull()] = 0\n",
    "        \n",
    "        assert tdf.shape[0]==100\n",
    "        input_users=Variable(torch.from_numpy(tdf.values)).to(device)\n",
    "        #input_mask=torch.from_numpy(train_mask.values).to(device)\n",
    "        loss=train_minibatch(input_users, vae, optimizer)\n",
    "        running_loss+=loss.item()\n",
    "        if (i+100)%44000==0:\n",
    "            val_rmse=validation(input_users_val, vae)\n",
    "            print ('Batch: {} | Step: {}/{} | Training Loss: {} | Validation RMSE: {}'.format(batch+1,int((i+100)/44000),5,running_loss,round(val_rmse,4) ))\n",
    "            running_loss=0\n",
    "            if(val_rmse<val_benchmark):\n",
    "                print ('%---Saving the model---%')\n",
    "                torch.save({\n",
    "                    'step':i+1,\n",
    "                    'autorec_state_dict': vae.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'batch':batch,\n",
    "                    'loss':val_rmse\n",
    "                    },'model_VAE.pth')\n",
    "                val_benchmark=val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
