{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from sklearn.utils import shuffle\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240447, 14277)\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('ratings.csv',names=['userID','movieID','rating','time'])\n",
    "df.drop('time',axis=1,inplace=True)\n",
    "users=[k for k,v in df['userID'].value_counts().iteritems() if v>2]\n",
    "movies=[k for k,v in df['movieID'].value_counts().iteritems() if v>10]\n",
    "df=df[(df['userID'].isin(users)) & (df['movieID'].isin(movies))]\n",
    "df=df.pivot(index='userID',columns='movieID',values='rating')\n",
    "print (df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=df.iloc[0:220000]\n",
    "test_df=df.iloc[230000:].reset_index(drop=True)\n",
    "val_df=df.iloc[220000:230000].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size_1, hidden_size_2):\n",
    "        super(VAE,self).__init__()\n",
    "        self.input_size=input_size\n",
    "        self.hidden_size_1=hidden_size_1\n",
    "        self.hidden_size_2=hidden_size_2\n",
    "        #self.training=training\n",
    "        \n",
    "        self.encoder_linear_l1=nn.Linear(input_size, hidden_size_1)\n",
    "        self.encoder_linear_l2=nn.Linear(hidden_size_1, 2*hidden_size_2)\n",
    "        \n",
    "        self.decode_linear_l1=nn.Linear(hidden_size_2, hidden_size_1)\n",
    "        self.decode_linear_l2=nn.Linear(hidden_size_1, input_size)\n",
    "        \n",
    "        self.sigmoid=nn.LogSigmoid()\n",
    "        \n",
    "    def forward(self, input_ratings):\n",
    "        mu,logvar=self.encode(input_ratings)\n",
    "        param=self.reparameterize(mu,logvar)\n",
    "        decoded=self.sigmoid(self.decode(param))\n",
    "        return decoded,mu,logvar\n",
    "    \n",
    "    def encode(self, input_ratings):\n",
    "        enc_out=F.relu(self.encoder_linear_l1(input_ratings))\n",
    "        enc_out=self.encoder_linear_l2(enc_out)\n",
    "        log_var=enc_out[:,self.hidden_size_2:]\n",
    "        mu=enc_out[:,:self.hidden_size_2]\n",
    "        return mu, log_var\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std=torch.exp(0.5*logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "    \n",
    "    def decode(self,param):\n",
    "        dec_out=F.relu(self.decode_linear_l1(param))\n",
    "        dec_out=self.decode_linear_l2(dec_out)\n",
    "        return dec_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_criterion(decoded,input_ratings,mu,logvar,annealing_coef):\n",
    "    bce_loss=-torch.mean(torch.sum(input_ratings*decoded,-1))\n",
    "    kl_divg=-0.5*torch.mean(torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1))\n",
    "    return bce_loss+annealing_coef*kl_divg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_minibatch(input_ratings, mask, vae, optimizer):\n",
    "    vae.train()\n",
    "    optimizer.zero_grad()\n",
    "    input_ratings=input_ratings.type(torch.cuda.FloatTensor)\n",
    "    #input_ratings=F.normalize(input_ratings,p=1)\n",
    "    output_ratings,mu,logvar=vae(input_ratings)\n",
    "    loss=loss_criterion(output_ratings,input_ratings,mu,logvar,annealing_coef=0.2)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(input_ratings, mask, vae):\n",
    "    with torch.no_grad():\n",
    "        vae.eval()\n",
    "        hit_list=[]\n",
    "        input_ratings=input_ratings.type(torch.cuda.FloatTensor)\n",
    "        #input_ratings=F.normalize(input_ratings,p=1)\n",
    "        for i in range(input_ratings.size(0)):\n",
    "            idx=torch.nonzero(mask[i])\n",
    "            if (idx.size(0)>5):\n",
    "                idx=idx[-1]\n",
    "                input_ratings[i][idx]=0\n",
    "                output_ratings=vae(input_ratings[i].unsqueeze(0))[0]\n",
    "                _,indices=torch.topk(output_ratings.squeeze(0),50)\n",
    "                if(idx in indices):\n",
    "                    hit_list.append(1)\n",
    "                else:\n",
    "                    hit_list.append(0)\n",
    "        return np.mean(hit_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae=VAE(input_size=train_df.shape[1], hidden_size_1=600, hidden_size_2=200)\n",
    "optimizer=optim.Adam(vae.parameters())\n",
    "device=torch.device('cuda')\n",
    "vae=vae.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_mask=val_df.copy()\n",
    "val_mask[~val_mask.isnull()] = 1  # not nan\n",
    "val_mask[val_mask.isnull()] = 0   # nan\n",
    "val_df[val_df.isnull()] = 0   # nan\n",
    "val_df[val_df<=3]=0\n",
    "val_df[val_df>3]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_users_val=torch.from_numpy(val_df.values).to(device).detach()\n",
    "mask_val=torch.from_numpy(val_mask.values).to(device).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('model_VAE.pth')\n",
    "autorec.load_state_dict(checkpoint['autorec_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "autorec.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1 | Step: 1/5 | Training Loss: 2.618682622909546 | Validation hit ratio: 0.0028\n",
      "%---Saving the model---%\n",
      "Batch: 1 | Step: 2/5 | Training Loss: 181.6016069613397 | Validation hit ratio: 0.1438\n",
      "%---Saving the model---%\n",
      "Batch: 1 | Step: 3/5 | Training Loss: 18.916725856717676 | Validation hit ratio: 0.1386\n",
      "Batch: 1 | Step: 4/5 | Training Loss: 6.533714386168867 | Validation hit ratio: 0.1398\n",
      "Batch: 1 | Step: 5/5 | Training Loss: 3.1022668709338177 | Validation hit ratio: 0.1378\n",
      "Batch: 2 | Step: 1/5 | Training Loss: 0.0006280505331233144 | Validation hit ratio: 0.1367\n",
      "Batch: 2 | Step: 2/5 | Training Loss: 1.1665297344734427 | Validation hit ratio: 0.1378\n",
      "Batch: 2 | Step: 3/5 | Training Loss: 0.42711660130589735 | Validation hit ratio: 0.1386\n",
      "Batch: 2 | Step: 4/5 | Training Loss: 0.3233424207137432 | Validation hit ratio: 0.1374\n",
      "Batch: 2 | Step: 5/5 | Training Loss: 0.06828319674968952 | Validation hit ratio: 0.1374\n",
      "Batch: 3 | Step: 1/5 | Training Loss: 0.00011142828589072451 | Validation hit ratio: 0.1367\n",
      "Batch: 3 | Step: 2/5 | Training Loss: 1686.8515023050932 | Validation hit ratio: 0.1367\n",
      "Batch: 3 | Step: 3/5 | Training Loss: 118.77057300987508 | Validation hit ratio: 0.1382\n",
      "Batch: 3 | Step: 4/5 | Training Loss: 0.35380937101581367 | Validation hit ratio: 0.1374\n",
      "Batch: 3 | Step: 5/5 | Training Loss: 0.04699705908205942 | Validation hit ratio: 0.1398\n",
      "Batch: 4 | Step: 1/5 | Training Loss: 4.068967609782703e-05 | Validation hit ratio: 0.1398\n",
      "Batch: 4 | Step: 2/5 | Training Loss: 15.312589596354883 | Validation hit ratio: 0.1398\n",
      "Batch: 4 | Step: 3/5 | Training Loss: 0.9539885574595246 | Validation hit ratio: 0.141\n",
      "Batch: 4 | Step: 4/5 | Training Loss: 0.10125930719004828 | Validation hit ratio: 0.139\n",
      "Batch: 4 | Step: 5/5 | Training Loss: 0.022836205942439847 | Validation hit ratio: 0.139\n",
      "Batch: 5 | Step: 1/5 | Training Loss: 2.781518196570687e-05 | Validation hit ratio: 0.139\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-acabd5ca6729>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtrain_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m   \u001b[0;31m# nan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mtdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtdf\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mtdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtdf\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0minput_users\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3115\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3116\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_setitem_frame\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_inplace_setting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_setitem_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3163\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_where\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_where\u001b[0;34m(self, cond, other, inplace, axis, level, errors, try_cast)\u001b[0m\n\u001b[1;32m   7623\u001b[0m             new_data = self._data.putmask(mask=cond, new=other, align=align,\n\u001b[1;32m   7624\u001b[0m                                           \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblock_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7625\u001b[0;31m                                           transpose=self._AXIS_REVERSED)\n\u001b[0m\u001b[1;32m   7626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mputmask\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   3694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3695\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mputmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3696\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'putmask'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3698\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m   3579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3580\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mgr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3581\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3582\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mputmask\u001b[0;34m(self, mask, new, align, inplace, axis, transpose, mgr)\u001b[0m\n\u001b[1;32m   1007\u001b[0m                                      \"length to masked array\")\n\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0;31m# maybe upcast me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_batches=10\n",
    "val_benchmark=0\n",
    "\n",
    "\n",
    "\n",
    "for batch in range(0,num_batches):\n",
    "    running_loss=0\n",
    "    #train_df = shuffle(train_df)\n",
    "    for i in range(0,train_df.shape[0],100):\n",
    "        #print(i)\n",
    "        tdf=(train_df.iloc[i:i+100].copy()).sample(frac=1)\n",
    "        train_mask=tdf.copy()\n",
    "        train_mask[~train_mask.isnull()] = 1  # not nan\n",
    "        train_mask[train_mask.isnull()] = 0   # nan\n",
    "        tdf[tdf.isnull()] = 0\n",
    "        tdf[tdf<=3]=0\n",
    "        tdf[tdf>3]=1\n",
    "        input_users=Variable(torch.from_numpy(tdf.values)).to(device)\n",
    "        input_mask=torch.from_numpy(train_mask.values).to(device)\n",
    "        loss=train_minibatch(input_users, input_mask, vae, optimizer)\n",
    "        running_loss+=loss.item()\n",
    "        if (i)%44000==0:\n",
    "            val_hr=validation(input_users_val, mask_val, vae)\n",
    "            print ('Batch: {} | Step: {}/{} | Training Loss: {} | Validation hit ratio: {}'.format(batch+1,int(i/44000)+1,5,running_loss,round(val_hr,4) ))\n",
    "            running_loss=0\n",
    "            if(val_hr>val_benchmark):\n",
    "                print ('%---Saving the model---%')\n",
    "                torch.save({\n",
    "                    'step':i+1,\n",
    "                    'autorec_state_dict': vae.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'batch':batch,\n",
    "                    'loss':val_hr\n",
    "                    },'model_VAE.pth')\n",
    "                val_benchmark=val_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
