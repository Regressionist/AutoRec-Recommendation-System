{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66182, 14162)\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('ratings.csv',names=['userID','movieID','rating','time'])\n",
    "df.drop('time',axis=1,inplace=True)\n",
    "users=[k for k,v in df['userID'].value_counts().iteritems() if v>5]\n",
    "movies=[k for k,v in df['movieID'].value_counts().iteritems() if v>10]\n",
    "df=df[(df['userID'].isin(users)) & (df['movieID'].isin(movies))]\n",
    "df=df.pivot(index='userID',columns='movieID',values='rating')\n",
    "print (df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=df.copy()\n",
    "mask[~mask.isnull()] = 1  # not nan\n",
    "mask[mask.isnull()] = 0   # nan\n",
    "df[df.isnull()] = 0   # nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix=df.values\n",
    "mask_matrix=mask.values\n",
    "train_matrix=df_matrix[0:50000]\n",
    "val_matrix=df_matrix[50000:60000]\n",
    "test_matrix=df_matrix[60000:]\n",
    "train_mask=mask_matrix[0:50000]\n",
    "val_mask=mask_matrix[50000:60000]\n",
    "test_mask=mask_matrix[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autorec(nn.Module):\n",
    "    def __init__(self, hidden_size, input_size):\n",
    "        super(Autorec, self).__init__()\n",
    "        self.input_size=input_size\n",
    "        self.hidden_size=hidden_size\n",
    "        \n",
    "        self.encoder=nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.decoder=nn.Linear(self.hidden_size, self.input_size)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "        self.decoder.weight.data = self.encoder.weight.data.transpose(0,1)\n",
    "        self.register_buffer('input', torch.zeros(input_size))\n",
    "        \n",
    "    def forward(self, input_ratings):\n",
    "        self.input=input_ratings\n",
    "        enc_out = self.encoder(input_ratings)\n",
    "        dec_out = 5*self.sigmoid(self.decoder(enc_out))\n",
    "        return dec_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_minibatch(input_ratings, mask, autorec, optimizer, criterion):\n",
    "    optimizer.zero_grad()\n",
    "    output_ratings=autorec(input_ratings.type(torch.cuda.FloatTensor))*mask.type(torch.cuda.FloatTensor)\n",
    "    loss=criterion(output_ratings,input_ratings.type(torch.cuda.FloatTensor))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return torch.sqrt(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(input_ratings, mask, autorec):\n",
    "    with torch.no_grad():\n",
    "        input_ratings=input_ratings.type(torch.cuda.FloatTensor)\n",
    "        output_ratings=autorec(input_ratings)*mask.type(torch.cuda.FloatTensor)\n",
    "        #loss=torch.sqrt(criterion(output_ratings,input_ratings.type(torch.cuda.FloatTensor)))\n",
    "        idx=torch.nonzero(mask)\n",
    "        loss=0\n",
    "        for i in idx:\n",
    "            loss+=((output_ratings[i[0]][i[1]]-input_ratings[i[0]][i[1]]).item())**2\n",
    "    return np.sqrt(loss/idx.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "autorec=Autorec(hidden_size=500,input_size=train_matrix.shape[1])\n",
    "optimizer=optim.Adam(autorec.parameters())\n",
    "criterion=nn.MSELoss()\n",
    "device=torch.device('cuda')\n",
    "autorec=autorec.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1 | Step: 1/10 | Training Loss: 0.0447 | Validation Loss: 1.9232\n",
      "%---Saving the model---%\n",
      "Batch: 1 | Step: 2/10 | Training Loss: 4.0059 | Validation Loss: 1.3475\n",
      "%---Saving the model---%\n",
      "Batch: 1 | Step: 3/10 | Training Loss: 3.3642 | Validation Loss: 1.2639\n",
      "%---Saving the model---%\n",
      "Batch: 1 | Step: 4/10 | Training Loss: 3.209 | Validation Loss: 1.2176\n",
      "%---Saving the model---%\n",
      "Batch: 1 | Step: 5/10 | Training Loss: 3.1295 | Validation Loss: 1.1834\n",
      "%---Saving the model---%\n",
      "Batch: 1 | Step: 6/10 | Training Loss: 3.0452 | Validation Loss: 1.1544\n",
      "%---Saving the model---%\n",
      "Batch: 1 | Step: 7/10 | Training Loss: 2.8858 | Validation Loss: 1.1269\n",
      "%---Saving the model---%\n",
      "Batch: 1 | Step: 8/10 | Training Loss: 2.9466 | Validation Loss: 1.1206\n",
      "%---Saving the model---%\n",
      "Batch: 1 | Step: 9/10 | Training Loss: 2.8858 | Validation Loss: 1.1026\n",
      "%---Saving the model---%\n",
      "Batch: 1 | Step: 10/10 | Training Loss: 2.8 | Validation Loss: 1.0962\n",
      "%---Saving the model---%\n",
      "Batch: 2 | Step: 1/10 | Training Loss: 0.0218 | Validation Loss: 1.0726\n",
      "%---Saving the model---%\n",
      "Batch: 2 | Step: 2/10 | Training Loss: 2.2177 | Validation Loss: 1.0704\n",
      "%---Saving the model---%\n",
      "Batch: 2 | Step: 3/10 | Training Loss: 1.9879 | Validation Loss: 1.0635\n",
      "%---Saving the model---%\n",
      "Batch: 2 | Step: 4/10 | Training Loss: 1.8831 | Validation Loss: 1.0505\n",
      "%---Saving the model---%\n",
      "Batch: 2 | Step: 5/10 | Training Loss: 1.8557 | Validation Loss: 1.0507\n",
      "Batch: 2 | Step: 6/10 | Training Loss: 1.7896 | Validation Loss: 1.0412\n",
      "%---Saving the model---%\n",
      "Batch: 2 | Step: 7/10 | Training Loss: 1.6863 | Validation Loss: 1.0378\n",
      "%---Saving the model---%\n",
      "Batch: 2 | Step: 8/10 | Training Loss: 1.7672 | Validation Loss: 1.0317\n",
      "%---Saving the model---%\n",
      "Batch: 2 | Step: 9/10 | Training Loss: 1.7548 | Validation Loss: 1.0328\n",
      "Batch: 2 | Step: 10/10 | Training Loss: 1.7229 | Validation Loss: 1.036\n",
      "Batch: 3 | Step: 1/10 | Training Loss: 0.0182 | Validation Loss: 1.0301\n",
      "%---Saving the model---%\n",
      "Batch: 3 | Step: 2/10 | Training Loss: 1.7202 | Validation Loss: 1.0241\n",
      "%---Saving the model---%\n",
      "Batch: 3 | Step: 3/10 | Training Loss: 1.6958 | Validation Loss: 1.0337\n",
      "Batch: 3 | Step: 4/10 | Training Loss: 1.6848 | Validation Loss: 1.035\n",
      "Batch: 3 | Step: 5/10 | Training Loss: 1.7384 | Validation Loss: 1.045\n",
      "Batch: 3 | Step: 6/10 | Training Loss: 1.7264 | Validation Loss: 1.0383\n",
      "%---Saving the model---%\n",
      "Batch: 3 | Step: 7/10 | Training Loss: 1.6673 | Validation Loss: 1.0431\n",
      "Batch: 3 | Step: 8/10 | Training Loss: 1.7581 | Validation Loss: 1.0407\n",
      "%---Saving the model---%\n",
      "Batch: 3 | Step: 9/10 | Training Loss: 1.7684 | Validation Loss: 1.0408\n",
      "Batch: 3 | Step: 10/10 | Training Loss: 1.7544 | Validation Loss: 1.051\n",
      "Batch: 4 | Step: 1/10 | Training Loss: 0.0176 | Validation Loss: 1.0537\n",
      "Batch: 4 | Step: 2/10 | Training Loss: 1.8358 | Validation Loss: 1.0493\n",
      "%---Saving the model---%\n",
      "Batch: 4 | Step: 3/10 | Training Loss: 1.8091 | Validation Loss: 1.0536\n",
      "Batch: 4 | Step: 4/10 | Training Loss: 1.8303 | Validation Loss: 1.0589\n",
      "Batch: 4 | Step: 5/10 | Training Loss: 1.8757 | Validation Loss: 1.0603\n",
      "Batch: 4 | Step: 6/10 | Training Loss: 1.8657 | Validation Loss: 1.0581\n",
      "%---Saving the model---%\n",
      "Batch: 4 | Step: 7/10 | Training Loss: 1.8 | Validation Loss: 1.0607\n",
      "Batch: 4 | Step: 8/10 | Training Loss: 1.9062 | Validation Loss: 1.0661\n",
      "Batch: 4 | Step: 9/10 | Training Loss: 1.8937 | Validation Loss: 1.069\n",
      "Batch: 4 | Step: 10/10 | Training Loss: 1.8901 | Validation Loss: 1.0761\n",
      "Batch: 5 | Step: 1/10 | Training Loss: 0.0175 | Validation Loss: 1.0754\n",
      "%---Saving the model---%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3e3e7bbc5e16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mrunning_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mval_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_users_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautorec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Batch: {} | Step: {}/{} | Training Loss: {} | Validation Loss: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mrunning_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-bd5821bfc3ae>\u001b[0m in \u001b[0;36mvalidation\u001b[0;34m(input_ratings, mask, autorec)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_ratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0minput_ratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_batches=50\n",
    "val_benchmark=10\n",
    "for batch in range(0,num_batches):\n",
    "    running_loss=0\n",
    "    input_users_val=torch.from_numpy(val_matrix).to(device).detach()\n",
    "    mask_val=torch.from_numpy(val_mask).to(device).detach()\n",
    "    for i in range(0,train_matrix.shape[0],50):\n",
    "        #print(i)\n",
    "        input_users=Variable(torch.from_numpy(train_matrix[i:i+50])).to(device)\n",
    "        input_mask=torch.from_numpy(train_mask[i:i+50]).to(device)\n",
    "        loss=train_minibatch(input_users, input_mask, autorec, optimizer, criterion)\n",
    "        running_loss+=loss.item()\n",
    "        if (i)%10000==0:\n",
    "            val_loss=validation(input_users_val, mask_val, autorec)\n",
    "            print ('Batch: {} | Step: {}/{} | Training Loss: {} | Validation Loss: {}'.format(batch+1,int(i/10000)+1,5,round(running_loss,4),round(val_loss,4)))\n",
    "            running_loss=0\n",
    "            if(val_loss<val_benchmark):\n",
    "                print ('%---Saving the model---%')\n",
    "                torch.save({\n",
    "                    'step':i+1,\n",
    "                    'autorec_state_dict': autorec.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'batch':batch,\n",
    "                    'loss':val_loss\n",
    "                    },'model.pth')\n",
    "                val_benchmark=val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
